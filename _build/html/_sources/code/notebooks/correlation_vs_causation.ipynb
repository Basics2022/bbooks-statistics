{"cells":[{"cell_type":"markdown","id":"aa24f530","metadata":{"id":"aa24f530"},"source":["\n","# \"Correlation is Not Causation\"\n","\n","In this article, some details about one of the most common sentence in statistics are given. Starting from the sentence \"Correlation is not causation\", the definitions of **correlation**, **independence**, and **causation** are discussed.\n","\n","<!--\n","Understanding these concepts is essential for data analysis, scientific research, and informed decision-making.\n","-->\n"]},{"cell_type":"markdown","id":"a4a05f58","metadata":{"id":"a4a05f58"},"source":["\n","## Definitions\n","\n","<!--\n","**Correlation** measures the statistical association between two variables. A high correlation indicates that the variables move together, but not necessarily that one causes the other.\n","\n","**Independence** means that knowing the value of one variable gives no information about the other.\n","\n","**Causation** implies that changes in one variable bring about changes in another.\n","\n","We will explore these using data, visualizations, and tests.\n","-->"]},{"cell_type":"markdown","source":["### Correlation\n","\n","Correlation measures any statistical relationship between two random variables, wheter it is statistically dependent or not, causal or not.\n","\n","The most common measure of correlation is **Pearson correlation**. Pearson correlation between two random variables $X$, $Y$ is defined as the ratio\n","\n","$$\\rho_{XY} := \\dfrac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y} \\ ,$$\n","\n","of the covariance $\\text{cov}(X,Y) = \\mathbb{E}\\left[ (X-\\mu_X) (Y-\\mu_Y) \\right]$, being $\\mu_Z$ the expected value of variable $Z$, $\\mu_Z = \\mathbb{E}\\left[ Z \\right]$, and $\\sigma_{Z}$ its standard deviation, $\\sigma_{Z} = \\sqrt{\\mathbb{E}\\left[ \\left( Z - \\mu_Z \\right)^2 \\right]}$."],"metadata":{"id":"0qxNyqMOwz0S"},"id":"0qxNyqMOwz0S"},{"cell_type":"markdown","source":["### Statistical independence\n","\n","Two random variables $X$, $Y$ are **statistically independent** if the conditional probability $p(X|Y)$ is equal to the unconditional probability $p(X)$,\n","\n","$$p(X|Y) = p(X)$$\n","\n","Thus, joint probability reads\n","\n","$$p(X,Y) = p(X|Y) p(Y) = p(X) p(Y) \\ , $$\n","\n","i.e. joint probability is the product of unconditional probabilities of independent random variables.\n","\n","As $p(X,Y) = p(Y|X) p(X)$, it also follows that $p(Y|X) = p(Y)$."],"metadata":{"id":"LTM26Og4yvsk"},"id":"LTM26Og4yvsk"},{"cell_type":"markdown","source":["#### Statistical independence implies no correlation\n","\n","As statistical independence  of variables $X$, $Y$ implies $p(X,Y) = p(X) p(Y)$, direct computation of the covariance $\\text{cov}(X,Y)$ reads\n","\n","$$\\begin{aligned}\n","  \\text{cov}(X,Y)\n","  & = \\mathbb{E}\\left[ \\left( X - \\mu_X \\right) \\left( Y - \\mu_Y \\right) \\right] = \\\\\n","  & = \\mathbb{E}\\left[ X - \\mu_X \\right] \\mathbb{E} \\left[ Y - \\mu_Y \\right] = 0 \\ .\n","\\end{aligned}$$"],"metadata":{"id":"GkUN2Lg40BaL"},"id":"GkUN2Lg40BaL"},{"cell_type":"markdown","source":["#### Correlation of samples drawn from independent random variables\n","\n","Sample covariance $\\hat{S}_N$ of $N$ samples $\\{ (X_n, Y_n) \\}_{n=1:N}$,\n","\n","$$\\hat{S}_N := \\dfrac{1}{N-1} \\sum_{n=1}^{N} \\left(X_n - \\overline{X}_N \\right) \\left(Y_n - \\overline{Y}_N \\right) \\ ,$$\n","\n","drawn from random variables $X$, $Y$ is a random variable with zero expected value, but its realizations are non-zero in general.\n","\n","In other words, samples of independent (and thus uncorrelated) variables have non-zero covariance and then non-zero correlation, in general."],"metadata":{"id":"Kj5A5uIa0IKp"},"id":"Kj5A5uIa0IKp"},{"cell_type":"markdown","source":["### Causality\n","\n","Causality is the relation between two events, in which one (the **cause**) is - at least partly - responsible for the other event (the **effect**), and the effect is - at least partly - dependent on the cause.\n","\n","Principle of causality relation implies that the cause comes before the effect.\n","\n","In general, an event may have multiple causes (that lie in its past) or have multiple effects."],"metadata":{"id":"dVMlnySc3LJp"},"id":"dVMlnySc3LJp"},{"cell_type":"markdown","source":["#### Necessary, sufficient and contributory causes\n","- $x$ is necessary for $y$ is the occurence of $y$ implies a prior occurrence of $x$\n","- $x$ is sufficient for $y$ if the occurrence of $x$ implies the subsequent occurrence of $y$\n","- $x$ is contributory for $y$ if it's one among several co-occurrent causes."],"metadata":{"id":"-JhnK-Jr4V4l"},"id":"-JhnK-Jr4V4l"},{"cell_type":"markdown","source":["## Pearl's work, *Causal Inference in Statistics: A Primer*\n","\n","\n","\n"],"metadata":{"id":"808mYwPU6JMr"},"id":"808mYwPU6JMr"},{"cell_type":"markdown","source":["### Ladder of causation\n","\n","Three levels of causation:\n","\n","- **Association** is defined as the conditional probability,\n","  \n","   $$P(A|B) \\ ,$$\n","\n","   and has no causal implication: there's no cause-effect directionality, or both can be caused by a third event\n","\n","- **Intervention** needs for an event to be performed (and not just observed), in the *minimal way*, with minimum intrusivity and unintended effects on the world. This action is represented mathematically using the *do-calculus* formalism. In order to quantify the effect of performing action $B$ on $A$, the probability\n","\n","   $$P(A| \\text{do}(B)) \\ ,$$\n","\n","   is required, being $\\text{do}(\\cdot)$ the operator representing the intervention\n","\n","- **Counterfactuals** involves the consideration of an alternate version of the cause (past event), and the analysis of the effects for the same experimental unit/system of interest. ...\n","\n","  $$P(A| B, C)$$\n","\n","   "],"metadata":{"id":"Dg2DMa_b6ds2"},"id":"Dg2DMa_b6ds2"},{"cell_type":"markdown","source":["### Model\n","\n","**Causal diagram**: directed graph showing causal relationship, built with nodes (set of variables) connected with arrows representing causal influence.\n","\n","**Elements.**\n","- **Junction** patterns:\n","  - chain, $A \\rightarrow B \\rightarrow C$\n","  - fork at $B$, $A \\leftarrow B \\rightarrow C$\n","  - collider at $B$, $A \\rightarrow B \\leftarrow C$\n","- **Node** types:\n","  - mediator\n","  - confounder: affects multiple outcomes, creating a positive correlation among them\n","  - instrumental variable...\n","  - ..."],"metadata":{"id":"o4l_Hrx_9tec"},"id":"o4l_Hrx_9tec"},{"cell_type":"markdown","source":["### Associations\n"],"metadata":{"id":"p2-kLMTH9gJp"},"id":"p2-kLMTH9gJp"},{"cell_type":"markdown","source":["### Interventions"],"metadata":{"id":"AGJ0lCQP_yTK"},"id":"AGJ0lCQP_yTK"},{"cell_type":"markdown","source":["### Counterfactuals\n"],"metadata":{"id":"OO3Py-ja_0Vh"},"id":"OO3Py-ja_0Vh"},{"cell_type":"markdown","source":["## Examples"],"metadata":{"id":"HljcXoOJysG2"},"id":"HljcXoOJysG2"},{"cell_type":"code","execution_count":null,"id":"2b97c110","metadata":{"id":"2b97c110"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy.stats import pearsonr, spearmanr, chi2_contingency\n","\n","sns.set(style='whitegrid')\n","np.random.seed(42)\n"]},{"cell_type":"code","execution_count":null,"id":"1ec681e9","metadata":{"id":"1ec681e9"},"outputs":[],"source":["\n","# Simulate correlated data\n","x = np.random.normal(0, 1, 100)\n","y = 2 * x + np.random.normal(0, 1, 100)\n","\n","df = pd.DataFrame({'x': x, 'y': y})\n","sns.scatterplot(data=df, x='x', y='y')\n","plt.title('Scatter Plot of Correlated Variables')\n","plt.show()\n","\n","# Pearson correlation coefficient\n","corr, p_value = pearsonr(df['x'], df['y'])\n","print(f\"Pearson correlation: {corr:.2f}, p-value: {p_value:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"e9155f70","metadata":{"id":"e9155f70"},"outputs":[],"source":["\n","# Simulate independent variables\n","a = np.random.normal(0, 1, 100)\n","b = np.random.normal(0, 1, 100)\n","\n","df_indep = pd.DataFrame({'a': a, 'b': b})\n","sns.scatterplot(data=df_indep, x='a', y='b')\n","plt.title('Scatter Plot of Independent Variables')\n","plt.show()\n","\n","# Correlation test\n","corr, p_value = pearsonr(df_indep['a'], df_indep['b'])\n","print(f\"Pearson correlation: {corr:.2f}, p-value: {p_value:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"id":"a7264d88","metadata":{"id":"a7264d88"},"outputs":[],"source":["\n","# Simulate a confounding variable\n","z = np.random.normal(0, 1, 100)\n","x = 2 * z + np.random.normal(0, 1, 100)\n","y = -3 * z + np.random.normal(0, 1, 100)\n","\n","df_spurious = pd.DataFrame({'x': x, 'y': y, 'z': z})\n","sns.scatterplot(data=df_spurious, x='x', y='y')\n","plt.title('Spurious Correlation via a Confounding Variable')\n","plt.show()\n","\n","corr, _ = pearsonr(df_spurious['x'], df_spurious['y'])\n","print(f\"Correlation between x and y: {corr:.2f} (spurious)\")\n"]},{"cell_type":"markdown","id":"910a357a","metadata":{"id":"910a357a"},"source":["\n","## Your Turn: Explore Causation\n","\n","Try changing the relationships between variables and test for correlation. Does correlation imply causation? Try creating a scenario where there is causation but low correlation.\n"]}],"metadata":{"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}